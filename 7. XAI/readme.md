Some models (linear) are inherently interpretable â€” for instance, Linear regression or Decision trees. 
LIME is a model-agnostic method that can be used for both tabular data and image classification tasks. 

1. LIME Explainer in Tabular Data for Diabetes dataset - 

![Lime Explainer in tabular data](https://github.com/newaz-aa/Hands-on-Machine-Learning-with-Python/blob/main/7.%20XAI/Figures/lime_2.png)

2. LIME Explainer in Cat vs Dog vs Panda Classification task - 

![Lime Explainer in image data](https://github.com/newaz-aa/Hands-on-Machine-Learning-with-Python/blob/main/7.%20XAI/Figures/Screenshot%202025-07-04%20230624.png)

The green color pixels increase the probability of the image being a panda. The red color pixels reduce it.

3. Decision Trees are inherently interpretable. Feature splits using GraphViz - 
![DT](https://github.com/newaz-aa/Hands-on-Machine-Learning-with-Python/blob/main/7.%20XAI/Figures/DT%20explainer.png)
